{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the Data  \n",
    "- ../datasets/attribute_set/custom_attr.csv  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import read_csv_with_dtypes \n",
    "import pandas as pd \n",
    "\n",
    "data = read_csv_with_dtypes(\"../datasets/attribute_set/custom_attr.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 289222 entries, 0 to 289221\n",
      "Columns: 1001 entries, paths to zippered\n",
      "dtypes: int8(1000), object(1)\n",
      "memory usage: 278.0+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paths</th>\n",
       "      <th>a-line</th>\n",
       "      <th>abstract</th>\n",
       "      <th>abstract chevron</th>\n",
       "      <th>abstract chevron print</th>\n",
       "      <th>abstract diamond</th>\n",
       "      <th>abstract floral</th>\n",
       "      <th>abstract floral print</th>\n",
       "      <th>abstract geo</th>\n",
       "      <th>abstract geo print</th>\n",
       "      <th>...</th>\n",
       "      <th>zeppelin</th>\n",
       "      <th>zig</th>\n",
       "      <th>zigzag</th>\n",
       "      <th>zip</th>\n",
       "      <th>zip-front</th>\n",
       "      <th>zip-pocket</th>\n",
       "      <th>zip-up</th>\n",
       "      <th>zipped</th>\n",
       "      <th>zipper</th>\n",
       "      <th>zippered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000001.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000002.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000003.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000004.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000005.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             paths  a-line  abstract  \\\n",
       "0  img/Sheer_Pleated-Front_Blouse/img_00000001.jpg       0         0   \n",
       "1  img/Sheer_Pleated-Front_Blouse/img_00000002.jpg       0         0   \n",
       "2  img/Sheer_Pleated-Front_Blouse/img_00000003.jpg       0         0   \n",
       "3  img/Sheer_Pleated-Front_Blouse/img_00000004.jpg       0         0   \n",
       "4  img/Sheer_Pleated-Front_Blouse/img_00000005.jpg       0         0   \n",
       "\n",
       "   abstract chevron  abstract chevron print  abstract diamond  \\\n",
       "0                 0                       0                 0   \n",
       "1                 0                       0                 0   \n",
       "2                 0                       0                 0   \n",
       "3                 0                       0                 0   \n",
       "4                 0                       0                 0   \n",
       "\n",
       "   abstract floral  abstract floral print  abstract geo  abstract geo print  \\\n",
       "0                0                      0             0                   0   \n",
       "1                0                      0             0                   0   \n",
       "2                0                      0             0                   0   \n",
       "3                0                      0             0                   0   \n",
       "4                0                      0             0                   0   \n",
       "\n",
       "   ...  zeppelin  zig  zigzag  zip  zip-front  zip-pocket  zip-up  zipped  \\\n",
       "0  ...         0    0       0    0          0           0       0       0   \n",
       "1  ...         0    0       0    0          0           0       0       0   \n",
       "2  ...         0    0       0    0          0           0       0       0   \n",
       "3  ...         0    0       0    0          0           0       0       0   \n",
       "4  ...         0    0       0    0          0           0       0       0   \n",
       "\n",
       "   zipper  zippered  \n",
       "0       0         0  \n",
       "1       0         0  \n",
       "2       0         0  \n",
       "3       0         0  \n",
       "4       0         0  \n",
       "\n",
       "[5 rows x 1001 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a-line',\n",
       " 'abstract',\n",
       " 'abstract chevron',\n",
       " 'abstract chevron print',\n",
       " 'abstract diamond']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABELS = list(data.columns.values[1:])\n",
    "LABELS[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../datasets/big_ds/img-001/'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base = \"../datasets/big_ds/img-001/\" \n",
    "base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paths</th>\n",
       "      <th>a-line</th>\n",
       "      <th>abstract</th>\n",
       "      <th>abstract chevron</th>\n",
       "      <th>abstract chevron print</th>\n",
       "      <th>abstract diamond</th>\n",
       "      <th>abstract floral</th>\n",
       "      <th>abstract floral print</th>\n",
       "      <th>abstract geo</th>\n",
       "      <th>abstract geo print</th>\n",
       "      <th>...</th>\n",
       "      <th>zeppelin</th>\n",
       "      <th>zig</th>\n",
       "      <th>zigzag</th>\n",
       "      <th>zip</th>\n",
       "      <th>zip-front</th>\n",
       "      <th>zip-pocket</th>\n",
       "      <th>zip-up</th>\n",
       "      <th>zipped</th>\n",
       "      <th>zipper</th>\n",
       "      <th>zippered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../datasets/big_ds/img-001/img/Sheer_Pleated-F...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../datasets/big_ds/img-001/img/Sheer_Pleated-F...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../datasets/big_ds/img-001/img/Sheer_Pleated-F...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../datasets/big_ds/img-001/img/Sheer_Pleated-F...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../datasets/big_ds/img-001/img/Sheer_Pleated-F...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               paths  a-line  abstract  \\\n",
       "0  ../datasets/big_ds/img-001/img/Sheer_Pleated-F...       0         0   \n",
       "1  ../datasets/big_ds/img-001/img/Sheer_Pleated-F...       0         0   \n",
       "2  ../datasets/big_ds/img-001/img/Sheer_Pleated-F...       0         0   \n",
       "3  ../datasets/big_ds/img-001/img/Sheer_Pleated-F...       0         0   \n",
       "4  ../datasets/big_ds/img-001/img/Sheer_Pleated-F...       0         0   \n",
       "\n",
       "   abstract chevron  abstract chevron print  abstract diamond  \\\n",
       "0                 0                       0                 0   \n",
       "1                 0                       0                 0   \n",
       "2                 0                       0                 0   \n",
       "3                 0                       0                 0   \n",
       "4                 0                       0                 0   \n",
       "\n",
       "   abstract floral  abstract floral print  abstract geo  abstract geo print  \\\n",
       "0                0                      0             0                   0   \n",
       "1                0                      0             0                   0   \n",
       "2                0                      0             0                   0   \n",
       "3                0                      0             0                   0   \n",
       "4                0                      0             0                   0   \n",
       "\n",
       "   ...  zeppelin  zig  zigzag  zip  zip-front  zip-pocket  zip-up  zipped  \\\n",
       "0  ...         0    0       0    0          0           0       0       0   \n",
       "1  ...         0    0       0    0          0           0       0       0   \n",
       "2  ...         0    0       0    0          0           0       0       0   \n",
       "3  ...         0    0       0    0          0           0       0       0   \n",
       "4  ...         0    0       0    0          0           0       0       0   \n",
       "\n",
       "   zipper  zippered  \n",
       "0       0         0  \n",
       "1       0         0  \n",
       "2       0         0  \n",
       "3       0         0  \n",
       "4       0         0  \n",
       "\n",
       "[5 rows x 1001 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.paths = data.paths.apply(lambda x: base + x) \n",
    "data.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(289222, 1001)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(289222, 1001)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data.shape)\n",
    "data = data.drop_duplicates() \n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000001.jpg</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000002.jpg</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000003.jpg</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000004.jpg</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000005.jpg</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              path  group\n",
       "0  img/Sheer_Pleated-Front_Blouse/img_00000001.jpg  train\n",
       "1  img/Sheer_Pleated-Front_Blouse/img_00000002.jpg  train\n",
       "2  img/Sheer_Pleated-Front_Blouse/img_00000003.jpg    val\n",
       "3  img/Sheer_Pleated-Front_Blouse/img_00000004.jpg  train\n",
       "4  img/Sheer_Pleated-Front_Blouse/img_00000005.jpg   test"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partitions = pd.read_csv(\"../datasets/attribute_set/list_eval_partition.txt\", delim_whitespace=True, header=None, names=[\"path\", \"group\"]) \n",
    "partitions.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../datasets/big_ds/img-001/img/Floral-Embroidered_Blouse/img_00000002.jpg',\n",
       " 'img/Floral-Embroidered_Blouse/img_00000002.jpg')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.paths[21134], partitions.path[21134]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((289222, 1001), (289222, 2))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape, partitions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paths</th>\n",
       "      <th>a-line</th>\n",
       "      <th>abstract</th>\n",
       "      <th>abstract chevron</th>\n",
       "      <th>abstract chevron print</th>\n",
       "      <th>abstract diamond</th>\n",
       "      <th>abstract floral</th>\n",
       "      <th>abstract floral print</th>\n",
       "      <th>abstract geo</th>\n",
       "      <th>abstract geo print</th>\n",
       "      <th>...</th>\n",
       "      <th>zig</th>\n",
       "      <th>zigzag</th>\n",
       "      <th>zip</th>\n",
       "      <th>zip-front</th>\n",
       "      <th>zip-pocket</th>\n",
       "      <th>zip-up</th>\n",
       "      <th>zipped</th>\n",
       "      <th>zipper</th>\n",
       "      <th>zippered</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../datasets/big_ds/img-001/img/Sheer_Pleated-F...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../datasets/big_ds/img-001/img/Sheer_Pleated-F...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../datasets/big_ds/img-001/img/Sheer_Pleated-F...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../datasets/big_ds/img-001/img/Sheer_Pleated-F...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../datasets/big_ds/img-001/img/Sheer_Pleated-F...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1002 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               paths  a-line  abstract  \\\n",
       "0  ../datasets/big_ds/img-001/img/Sheer_Pleated-F...       0         0   \n",
       "1  ../datasets/big_ds/img-001/img/Sheer_Pleated-F...       0         0   \n",
       "2  ../datasets/big_ds/img-001/img/Sheer_Pleated-F...       0         0   \n",
       "3  ../datasets/big_ds/img-001/img/Sheer_Pleated-F...       0         0   \n",
       "4  ../datasets/big_ds/img-001/img/Sheer_Pleated-F...       0         0   \n",
       "\n",
       "   abstract chevron  abstract chevron print  abstract diamond  \\\n",
       "0                 0                       0                 0   \n",
       "1                 0                       0                 0   \n",
       "2                 0                       0                 0   \n",
       "3                 0                       0                 0   \n",
       "4                 0                       0                 0   \n",
       "\n",
       "   abstract floral  abstract floral print  abstract geo  abstract geo print  \\\n",
       "0                0                      0             0                   0   \n",
       "1                0                      0             0                   0   \n",
       "2                0                      0             0                   0   \n",
       "3                0                      0             0                   0   \n",
       "4                0                      0             0                   0   \n",
       "\n",
       "   ...  zig  zigzag  zip  zip-front  zip-pocket  zip-up  zipped  zipper  \\\n",
       "0  ...    0       0    0          0           0       0       0       0   \n",
       "1  ...    0       0    0          0           0       0       0       0   \n",
       "2  ...    0       0    0          0           0       0       0       0   \n",
       "3  ...    0       0    0          0           0       0       0       0   \n",
       "4  ...    0       0    0          0           0       0       0       0   \n",
       "\n",
       "   zippered  group  \n",
       "0         0  train  \n",
       "1         0  train  \n",
       "2         0    val  \n",
       "3         0  train  \n",
       "4         0   test  \n",
       "\n",
       "[5 rows x 1002 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"group\"] = partitions.group\n",
    "data.head() "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle Attrbute Type \n",
    "\n",
    "<b>Attribute Type</b>  \n",
    "- \"1\" represents texture-related attributes, \n",
    "- \"2\" represents fabric-related attributes, \n",
    "- \"3\" represents shape-related attributes, \n",
    "- \"4\" represents part-related attributes, \n",
    "- \"5\" represents style-related attributes;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attribute_name</th>\n",
       "      <th>attribute_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a-line</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abstract</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abstract chevron</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abstract chevron print</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abstract diamond</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           attribute_name  attribute_type\n",
       "0                  a-line               3\n",
       "1                abstract               1\n",
       "2        abstract chevron               1\n",
       "3  abstract chevron print               1\n",
       "4        abstract diamond               1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attr = pd.read_csv(\"../datasets/attribute_set/custom_attr_definitions.csv\", index_col=0)\n",
    "attr.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 2, 4, 3, 1], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attr.attribute_type.value_counts().index.to_numpy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part Related Attributes \"4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attribute_name</th>\n",
       "      <th>attribute_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>arrow collar</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>asymmetrical hem</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>back bow</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>back cutout</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>back knit</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      attribute_name  attribute_type\n",
       "22      arrow collar               4\n",
       "26  asymmetrical hem               4\n",
       "31          back bow               4\n",
       "32       back cutout               4\n",
       "33         back knit               4"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attr[attr.attribute_type == 4].head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(216, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attr[attr.attribute_type == 4].shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "df_category_4 = data.loc[:,np.concatenate([['paths', 'group'], attr[attr.attribute_type == 4].iloc[:,0].values])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(289222, 218)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_category_4.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "\n",
    "def create_pi(df):\n",
    "    zeros = 0\n",
    "    ones = 0 \n",
    "    for i in range(2, df.shape[1]):\n",
    "        zeros = zeros + df.iloc[:, i].value_counts().to_numpy()[0] \n",
    "        ones = ones + df.iloc[:, i].value_counts().to_numpy()[1]  \n",
    "\n",
    "    \n",
    "    data_m = [ones, zeros]\n",
    "    keys = ['Positive', 'Negative']\n",
    "    \n",
    "    palette_color = seaborn.color_palette('bright')\n",
    "    plt.pie(data_m, labels=keys, colors=palette_color, autopct='%.0f%%')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_pi(df_category_4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shape Related Attributes \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(289222, 182)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_category_3 = data.loc[:,np.concatenate([['paths', 'group'], attr[attr.attribute_type == 3].iloc[:,0].values])]\n",
    "df_category_3.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baja\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    289000\n",
       "1       222\n",
       "Name: baja, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_category_3.columns[6])\n",
    "df_category_3.iloc[:, 6].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n(df: pd.DataFrame, n: int):\n",
    "    top25 = [] \n",
    "    for col in df.columns[2:]: \n",
    "        top25.append({\n",
    "            \"col\": col, \n",
    "            \"value\": df[col].value_counts()[1]\n",
    "        })\n",
    "\n",
    "    res = pd.DataFrame(top25).sort_values(by=\"value\", ascending=False) \n",
    "    return res[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['paths', 'group'] + get_top_n(df_category_3, 30)['col'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_pi(df_category_3.loc[:, cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(289222, 232)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_category_5 = data.loc[:,np.concatenate([['paths', 'group'], attr[attr.attribute_type == 5].iloc[:,0].values])]\n",
    "df_category_5.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_pi(df_category_5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((289222, 232), (289222, 182), (289222, 218))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_category_5.shape, df_category_3.shape, df_category_4.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data Pipeline by using tf.data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((209222, 182), (40000, 182), (40000, 182))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_category_3[df_category_3.group == 'train'].shape,  df_category_3[df_category_3.group == 'val'].shape,  df_category_3[df_category_3.group == 'test'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prev: (289222, 182)\n",
      "Nothing changed.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(132269, 182)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from helpers import row_cleaner, col_cleaner\n",
    "\n",
    "print(\"Prev:\", df_category_3.shape)\n",
    "df_category_3 = col_cleaner(row_cleaner(df_category_3)) \n",
    "\n",
    "df_category_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132269, 32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['paths', 'group'] + get_top_n(df_category_3, 30)['col'].to_list() \n",
    "df_category_3 = df_category_3.loc[:, cols]\n",
    "\n",
    "df_category_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paths</th>\n",
       "      <th>maxi</th>\n",
       "      <th>hirt</th>\n",
       "      <th>fit</th>\n",
       "      <th>bodycon</th>\n",
       "      <th>crop</th>\n",
       "      <th>kater</th>\n",
       "      <th>mini</th>\n",
       "      <th>muscle</th>\n",
       "      <th>kinny</th>\n",
       "      <th>...</th>\n",
       "      <th>heath</th>\n",
       "      <th>longline</th>\n",
       "      <th>tunic</th>\n",
       "      <th>wrap</th>\n",
       "      <th>peasant</th>\n",
       "      <th>oversized</th>\n",
       "      <th>pullover</th>\n",
       "      <th>capri</th>\n",
       "      <th>rise</th>\n",
       "      <th>moto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../datasets/big_ds/img-001/img/Floral_Print_Ra...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../datasets/big_ds/img-001/img/Heathered_Knit_...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../datasets/big_ds/img-001/img/Boxy_Slit-Sleev...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../datasets/big_ds/img-001/img/Pizza_Party_Tee...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../datasets/big_ds/img-001/img/Cutout-Back_Mus...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               paths  maxi  hirt  fit  \\\n",
       "0  ../datasets/big_ds/img-001/img/Floral_Print_Ra...     0     0    0   \n",
       "1  ../datasets/big_ds/img-001/img/Heathered_Knit_...     0     0    0   \n",
       "2  ../datasets/big_ds/img-001/img/Boxy_Slit-Sleev...     0     0    0   \n",
       "3  ../datasets/big_ds/img-001/img/Pizza_Party_Tee...     0     1    0   \n",
       "4  ../datasets/big_ds/img-001/img/Cutout-Back_Mus...     0     0    0   \n",
       "\n",
       "   bodycon  crop  kater  mini  muscle  kinny  ...  heath  longline  tunic  \\\n",
       "0        0     0      0     0       0      0  ...      0         0      0   \n",
       "1        0     0      1     0       0      0  ...      0         0      0   \n",
       "2        0     0      0     0       0      0  ...      0         0      0   \n",
       "3        0     0      0     0       0      0  ...      0         0      0   \n",
       "4        0     0      0     0       1      0  ...      0         0      0   \n",
       "\n",
       "   wrap  peasant  oversized  pullover  capri  rise  moto  \n",
       "0     0        0          0         0      0     0     0  \n",
       "1     0        0          0         0      0     0     0  \n",
       "2     0        0          0         0      0     0     0  \n",
       "3     0        0          0         0      0     0     0  \n",
       "4     0        0          0         0      0     0     0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TRAIN_SIZE = df_category_3[df_category_3.group == 'train'].shape[0]\n",
    "TRAIN_SIZE = 60000\n",
    "vall = df_category_3[df_category_3.group == 'val'].sample(frac=1, random_state = 42)\n",
    "data = pd.concat([df_category_3[df_category_3.group == 'train'].iloc[:TRAIN_SIZE,:].sample(frac=1),  vall]\n",
    "                ).reset_index(drop=True).drop(['group'], axis=1)\n",
    "\n",
    "data.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['../datasets/big_ds/img-001/img/Floral_Print_Raglan_Tee/img_00000007.jpg',\n",
       "       '../datasets/big_ds/img-001/img/Heathered_Knit_Skater_Skirt/img_00000001.jpg',\n",
       "       '../datasets/big_ds/img-001/img/Boxy_Slit-Sleeve_Top/img_00000012.jpg',\n",
       "       '../datasets/big_ds/img-001/img/Pizza_Party_Tee/img_00000054.jpg',\n",
       "       '../datasets/big_ds/img-001/img/Cutout-Back_Muscle_Tee/img_00000007.jpg'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fnames = data.paths.to_numpy()  \n",
    "fnames[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78183"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "\n",
    "ds_size = data.shape[0] \n",
    "# number_of_selected_samples = 2000 \n",
    "\n",
    "filelist_ds = tf.data.Dataset.from_tensor_slices(fnames) \n",
    "\n",
    "filelist_ds.cardinality().numpy() "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom tf Helpers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(file_path):\n",
    "    \"\"\"\n",
    "        file_path: the file path for the image that you want to select\n",
    "    \"\"\"\n",
    "    labels = data.loc[data.paths == file_path].to_numpy().squeeze()[1:].astype(\"int64\")\n",
    "    return tf.convert_to_tensor(labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(30,), dtype=int64, numpy=\n",
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_label(fnames[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize and scale the images so that we can save time in training  \n",
    "IMG_WIDTH, IMG_HEIGHT = 224, 224 \n",
    "def decode_img(img):\n",
    "    \"\"\"\n",
    "        img: img is the image \n",
    "    \"\"\" \n",
    "    #color images \n",
    "    img = tf.image.decode_jpeg(img, channels=3) \n",
    "    img = tf.image.convert_image_dtype(img, tf.float32) \n",
    "    img = tf.image.resize(img, [IMG_WIDTH, IMG_HEIGHT]) \n",
    "    img = img / tf.constant(256, dtype=tf.float32)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_images_labels(file_path: tf.Tensor): \n",
    "    label = get_label(file_path) \n",
    "    img = tf.io.read_file(file_path) \n",
    "    img = decode_img(img) \n",
    "    return img, label "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Test Split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.80 \n",
    "ds_train = filelist_ds.take(TRAIN_SIZE) \n",
    "ds_test = filelist_ds.skip(TRAIN_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process All the Images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = ds_train.map(lambda x: \n",
    "                        tf.py_function(func=combine_images_labels, \n",
    "                                       inp=[x], # input of the function \n",
    "                                       Tout=(tf.float32,tf.int64)),  # return type \n",
    "                        num_parallel_calls=tf.data.AUTOTUNE, # parallelizing data extraction \n",
    "                        deterministic=False \n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test= ds_test.map(lambda x: tf.py_function(func=combine_images_labels,\n",
    "          inp=[x], Tout=(tf.float32,tf.int64)),\n",
    "          num_parallel_calls=tf.data.AUTOTUNE,\n",
    "          deterministic=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data Pipeline \n",
    "\n",
    "- **batch**(): Combines consecutive elements of this dataset into batches.\n",
    "- **cache**(): Caches the elements in this dataset. he first time the dataset is iterated over, its elements will be cached either in the specified file or in memory.Subsequent iterations will use the cached data.\n",
    "- **prefetch**(): Creates a Dataset that prefetches elements from this dataset. Most dataset input pipelines should end with a call to *prefetch*. This allows later elements to be prepared while the current element is being processed. This often improves latency and throughput, at the cost of using additional memory to store prefetched elements.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train_batched = ds_train.batch(BATCH_SIZE).cache().prefetch(tf.data.experimental.AUTOTUNE) \n",
    "ds_test_batched = ds_test.batch(BATCH_SIZE).cache().prefetch(tf.data.experimental.AUTOTUNE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1875"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train_batched.cardinality().numpy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nr_of_classes = len(data.columns) - 1  \n",
    "nr_of_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1875 * 32 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1:Fine Grained VGG16 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras \n",
    "base_model = keras.applications.VGG16(\n",
    "    weights=\"imagenet\", # load weights pre-trained on ImageNet. \n",
    "    input_shape=(IMG_WIDTH, IMG_HEIGHT, 3), # VGG16 expects min 32 x 32 \n",
    "    include_top = False # do not include output layer of the image net vgg \n",
    ")\n",
    "base_model.trainable = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(IMG_WIDTH,IMG_HEIGHT,3))\n",
    "x = tf.cast(inputs, tf.float32)\n",
    "x = tf.keras.applications.vgg16.preprocess_input(x)   \n",
    "x = base_model(x) \n",
    "x = keras.layers.GlobalAveragePooling2D()(x) \n",
    "\n",
    "initializer = tf.keras.initializers.GlorotUniform(seed=42) \n",
    "activation = tf.keras.activations.sigmoid  \n",
    "\n",
    "outputs = keras.layers.Dense(nr_of_classes,\n",
    "                             kernel_initializer=initializer, \n",
    "                             activation=activation)(x) \n",
    "\n",
    "model_1 = keras.Model(inputs, outputs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.compile(optimizer=keras.optimizers.Adam(),\n",
    "              loss=keras.losses.BinaryCrossentropy(), # default from_logits=False\n",
    "              metrics=[keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5) \n",
    "checkpoint_path = \"checkpoints/NORMAL_DATASET/STEP_60thousand/Model 1: VGG/checkpoint_VGG_Model_1-{epoch:01d}.ckpt\" \n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                         save_weights_only=True,\n",
    "                                                         save_best_only=False,\n",
    "                                                         verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x23077b103a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# model_1.load_weights(previous_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - ETA: 0s - loss: 0.1479 - tp: 436.0000 - fp: 8076.0000 - tn: 1731448.0000 - fn: 60040.0000 - accuracy: 0.9622 - precision: 0.0512 - recall: 0.0072   "
     ]
    },
    {
     "ename": "StagingError",
     "evalue": "in user code:\n\n    File \"c:\\ProgramData\\Anaconda3\\envs\\env_similar-products\\lib\\site-packages\\keras\\engine\\training.py\", line 1557, in test_function  *\n        return step_function(self, iterator)\n    File \"c:\\ProgramData\\Anaconda3\\envs\\env_similar-products\\lib\\site-packages\\keras\\engine\\training.py\", line 1546, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\ProgramData\\Anaconda3\\envs\\env_similar-products\\lib\\site-packages\\keras\\engine\\training.py\", line 1535, in run_step  **\n        outputs = model.test_step(data)\n    File \"c:\\ProgramData\\Anaconda3\\envs\\env_similar-products\\lib\\site-packages\\keras\\engine\\training.py\", line 1499, in test_step\n        y_pred = self(x, training=False)\n    File \"c:\\ProgramData\\Anaconda3\\envs\\env_similar-products\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n\n    OverflowError: Exception encountered when calling layer \"tf.__operators__.getitem\" (type SlicingOpLambda).\n    \n    Python int too large to convert to C long\n    \n    Call arguments received by layer \"tf.__operators__.getitem\" (type SlicingOpLambda):\n      â€¢ tensor=tf.Tensor(shape=(None, 224, 224, 3), dtype=float32)\n      â€¢ slice_spec=('Ellipsis', {'start': 'None', 'stop': 'None', 'step': '-1'})\n      â€¢ var=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStagingError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\13\\ipykernel_11184\\2976827453.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m history_model_1 = model_1.fit(ds_train_batched, \n\u001b[0m\u001b[0;32m      2\u001b[0m                             \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                             \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mds_test_batched\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheckpoint_callback\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                             )\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\env_similar-products\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\env_similar-products\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1125\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1126\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1127\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1128\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1129\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mStagingError\u001b[0m: in user code:\n\n    File \"c:\\ProgramData\\Anaconda3\\envs\\env_similar-products\\lib\\site-packages\\keras\\engine\\training.py\", line 1557, in test_function  *\n        return step_function(self, iterator)\n    File \"c:\\ProgramData\\Anaconda3\\envs\\env_similar-products\\lib\\site-packages\\keras\\engine\\training.py\", line 1546, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\ProgramData\\Anaconda3\\envs\\env_similar-products\\lib\\site-packages\\keras\\engine\\training.py\", line 1535, in run_step  **\n        outputs = model.test_step(data)\n    File \"c:\\ProgramData\\Anaconda3\\envs\\env_similar-products\\lib\\site-packages\\keras\\engine\\training.py\", line 1499, in test_step\n        y_pred = self(x, training=False)\n    File \"c:\\ProgramData\\Anaconda3\\envs\\env_similar-products\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n\n    OverflowError: Exception encountered when calling layer \"tf.__operators__.getitem\" (type SlicingOpLambda).\n    \n    Python int too large to convert to C long\n    \n    Call arguments received by layer \"tf.__operators__.getitem\" (type SlicingOpLambda):\n      â€¢ tensor=tf.Tensor(shape=(None, 224, 224, 3), dtype=float32)\n      â€¢ slice_spec=('Ellipsis', {'start': 'None', 'stop': 'None', 'step': '-1'})\n      â€¢ var=None\n"
     ]
    }
   ],
   "source": [
    "history_model_1 = model_1.fit(ds_train_batched, \n",
    "                            epochs=10,\n",
    "                            validation_data =ds_test_batched,\n",
    "                            callbacks=[early_stopping, checkpoint_callback]\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\13\\ipykernel_18328\\1222367645.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../trained_models/IN_SHOP_Models/model_1_vgg.h5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model_1' is not defined"
     ]
    }
   ],
   "source": [
    "model_1.save(\"../trained_models/IN_SHOP_Models/model_1_vgg.h5\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=(TensorSpec(shape=<unknown>, dtype=tf.float32, name=None), TensorSpec(shape=<unknown>, dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train_batched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history_model_1.history).to_csv(\"../trained_models/IN_SHOP_Models/model_1_vgg_RESULT_2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: Efficient Net "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "efficient_net = tf.keras.applications.EfficientNetB0(include_top=False)\n",
    "efficient_net.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras \n",
    "inputs = keras.Input(shape=(IMG_WIDTH,IMG_HEIGHT,3)) \n",
    "x = efficient_net(inputs) \n",
    "x = keras.layers.GlobalAveragePooling2D()(x) \n",
    "\n",
    "initializer = tf.keras.initializers.GlorotUniform(seed=42) \n",
    "activation = tf.keras.activations.sigmoid  \n",
    "\n",
    "outputs = keras.layers.Dense(nr_of_classes,\n",
    "                             kernel_initializer=initializer, \n",
    "                             activation=activation)(x) \n",
    "\n",
    "model_2 = keras.Model(inputs, outputs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall')\n",
    "]\n",
    "\n",
    "model_2.compile(optimizer=keras.optimizers.Adam(),\n",
    "              loss=keras.losses.BinaryCrossentropy(), # default from_logits=False\n",
    "              metrics=METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x234804c1640>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_2.load_weights(\"checkpoints/in-shop_ds_model2/checkpoint_Efficient_Base.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5) \n",
    "checkpoint_path = \"checkpoints/in-shop_ds_model2_STEP_3/checkpoint_Efficient_Base.ckpt\" \n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                         save_weights_only=True,\n",
    "                                                         save_best_only=False,\n",
    "                                                         verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "463/463 [==============================] - ETA: 0s - loss: 0.1703 - tp: 62134.0000 - fp: 42225.0000 - tn: 4811905.0000 - fn: 224888.0000 - accuracy: 0.9480 - precision: 0.5954 - recall: 0.2165\n",
      "Epoch 1: saving model to checkpoints/in-shop_ds_model2_STEP_3\\checkpoint_Efficient_Base.ckpt\n",
      "463/463 [==============================] - 376s 781ms/step - loss: 0.1703 - tp: 62134.0000 - fp: 42225.0000 - tn: 4811905.0000 - fn: 224888.0000 - accuracy: 0.9480 - precision: 0.5954 - recall: 0.2165 - val_loss: 0.1547 - val_tp: 16258.0000 - val_fp: 6287.0000 - val_tn: 1207245.0000 - val_fn: 55498.0000 - val_accuracy: 0.9519 - val_precision: 0.7211 - val_recall: 0.2266\n",
      "Epoch 2/10\n",
      "463/463 [==============================] - ETA: 0s - loss: 0.1516 - tp: 71549.0000 - fp: 30430.0000 - tn: 4823700.0000 - fn: 215473.0000 - accuracy: 0.9522 - precision: 0.7016 - recall: 0.2493\n",
      "Epoch 2: saving model to checkpoints/in-shop_ds_model2_STEP_3\\checkpoint_Efficient_Base.ckpt\n",
      "463/463 [==============================] - 383s 822ms/step - loss: 0.1516 - tp: 71549.0000 - fp: 30430.0000 - tn: 4823700.0000 - fn: 215473.0000 - accuracy: 0.9522 - precision: 0.7016 - recall: 0.2493 - val_loss: 0.1506 - val_tp: 17393.0000 - val_fp: 6585.0000 - val_tn: 1206947.0000 - val_fn: 54363.0000 - val_accuracy: 0.9526 - val_precision: 0.7254 - val_recall: 0.2424\n",
      "Epoch 3/10\n",
      "463/463 [==============================] - ETA: 0s - loss: 0.1470 - tp: 75705.0000 - fp: 30986.0000 - tn: 4823144.0000 - fn: 211317.0000 - accuracy: 0.9529 - precision: 0.7096 - recall: 0.2638\n",
      "Epoch 3: saving model to checkpoints/in-shop_ds_model2_STEP_3\\checkpoint_Efficient_Base.ckpt\n",
      "463/463 [==============================] - 389s 836ms/step - loss: 0.1470 - tp: 75705.0000 - fp: 30986.0000 - tn: 4823144.0000 - fn: 211317.0000 - accuracy: 0.9529 - precision: 0.7096 - recall: 0.2638 - val_loss: 0.1484 - val_tp: 18115.0000 - val_fp: 6857.0000 - val_tn: 1206675.0000 - val_fn: 53641.0000 - val_accuracy: 0.9529 - val_precision: 0.7254 - val_recall: 0.2525\n",
      "Epoch 4/10\n",
      "463/463 [==============================] - ETA: 0s - loss: 0.1440 - tp: 78448.0000 - fp: 31352.0000 - tn: 4822778.0000 - fn: 208574.0000 - accuracy: 0.9533 - precision: 0.7145 - recall: 0.2733\n",
      "Epoch 4: saving model to checkpoints/in-shop_ds_model2_STEP_3\\checkpoint_Efficient_Base.ckpt\n",
      "463/463 [==============================] - 407s 875ms/step - loss: 0.1440 - tp: 78448.0000 - fp: 31352.0000 - tn: 4822778.0000 - fn: 208574.0000 - accuracy: 0.9533 - precision: 0.7145 - recall: 0.2733 - val_loss: 0.1471 - val_tp: 18652.0000 - val_fp: 7088.0000 - val_tn: 1206444.0000 - val_fn: 53104.0000 - val_accuracy: 0.9532 - val_precision: 0.7246 - val_recall: 0.2599\n",
      "Epoch 5/10\n",
      "463/463 [==============================] - ETA: 0s - loss: 0.1416 - tp: 80641.0000 - fp: 31457.0000 - tn: 4822673.0000 - fn: 206381.0000 - accuracy: 0.9537 - precision: 0.7194 - recall: 0.2810\n",
      "Epoch 5: saving model to checkpoints/in-shop_ds_model2_STEP_3\\checkpoint_Efficient_Base.ckpt\n",
      "463/463 [==============================] - 390s 838ms/step - loss: 0.1416 - tp: 80641.0000 - fp: 31457.0000 - tn: 4822673.0000 - fn: 206381.0000 - accuracy: 0.9537 - precision: 0.7194 - recall: 0.2810 - val_loss: 0.1459 - val_tp: 19119.0000 - val_fp: 7279.0000 - val_tn: 1206253.0000 - val_fn: 52637.0000 - val_accuracy: 0.9534 - val_precision: 0.7243 - val_recall: 0.2664\n",
      "Epoch 6/10\n",
      "463/463 [==============================] - ETA: 0s - loss: 0.1396 - tp: 82255.0000 - fp: 31566.0000 - tn: 4822564.0000 - fn: 204767.0000 - accuracy: 0.9540 - precision: 0.7227 - recall: 0.2866\n",
      "Epoch 6: saving model to checkpoints/in-shop_ds_model2_STEP_3\\checkpoint_Efficient_Base.ckpt\n",
      "463/463 [==============================] - 378s 813ms/step - loss: 0.1396 - tp: 82255.0000 - fp: 31566.0000 - tn: 4822564.0000 - fn: 204767.0000 - accuracy: 0.9540 - precision: 0.7227 - recall: 0.2866 - val_loss: 0.1451 - val_tp: 19415.0000 - val_fp: 7412.0000 - val_tn: 1206120.0000 - val_fn: 52341.0000 - val_accuracy: 0.9535 - val_precision: 0.7237 - val_recall: 0.2706\n",
      "Epoch 7/10\n",
      "463/463 [==============================] - ETA: 0s - loss: 0.1380 - tp: 83670.0000 - fp: 31731.0000 - tn: 4822399.0000 - fn: 203352.0000 - accuracy: 0.9543 - precision: 0.7250 - recall: 0.2915\n",
      "Epoch 7: saving model to checkpoints/in-shop_ds_model2_STEP_3\\checkpoint_Efficient_Base.ckpt\n",
      "463/463 [==============================] - 349s 754ms/step - loss: 0.1380 - tp: 83670.0000 - fp: 31731.0000 - tn: 4822399.0000 - fn: 203352.0000 - accuracy: 0.9543 - precision: 0.7250 - recall: 0.2915 - val_loss: 0.1444 - val_tp: 19671.0000 - val_fp: 7512.0000 - val_tn: 1206020.0000 - val_fn: 52085.0000 - val_accuracy: 0.9536 - val_precision: 0.7237 - val_recall: 0.2741\n",
      "Epoch 8/10\n",
      "463/463 [==============================] - ETA: 0s - loss: 0.1365 - tp: 85136.0000 - fp: 31782.0000 - tn: 4822348.0000 - fn: 201886.0000 - accuracy: 0.9545 - precision: 0.7282 - recall: 0.2966\n",
      "Epoch 8: saving model to checkpoints/in-shop_ds_model2_STEP_3\\checkpoint_Efficient_Base.ckpt\n",
      "463/463 [==============================] - 356s 769ms/step - loss: 0.1365 - tp: 85136.0000 - fp: 31782.0000 - tn: 4822348.0000 - fn: 201886.0000 - accuracy: 0.9545 - precision: 0.7282 - recall: 0.2966 - val_loss: 0.1439 - val_tp: 20009.0000 - val_fp: 7765.0000 - val_tn: 1205767.0000 - val_fn: 51747.0000 - val_accuracy: 0.9537 - val_precision: 0.7204 - val_recall: 0.2788\n",
      "Epoch 9/10\n",
      "463/463 [==============================] - ETA: 0s - loss: 0.1352 - tp: 85799.0000 - fp: 31865.0000 - tn: 4822265.0000 - fn: 201223.0000 - accuracy: 0.9547 - precision: 0.7292 - recall: 0.2989\n",
      "Epoch 9: saving model to checkpoints/in-shop_ds_model2_STEP_3\\checkpoint_Efficient_Base.ckpt\n",
      "463/463 [==============================] - 391s 841ms/step - loss: 0.1352 - tp: 85799.0000 - fp: 31865.0000 - tn: 4822265.0000 - fn: 201223.0000 - accuracy: 0.9547 - precision: 0.7292 - recall: 0.2989 - val_loss: 0.1435 - val_tp: 20065.0000 - val_fp: 7721.0000 - val_tn: 1205811.0000 - val_fn: 51691.0000 - val_accuracy: 0.9538 - val_precision: 0.7221 - val_recall: 0.2796\n",
      "Epoch 10/10\n",
      "463/463 [==============================] - ETA: 0s - loss: 0.1340 - tp: 87296.0000 - fp: 32037.0000 - tn: 4822093.0000 - fn: 199726.0000 - accuracy: 0.9549 - precision: 0.7315 - recall: 0.3041\n",
      "Epoch 10: saving model to checkpoints/in-shop_ds_model2_STEP_3\\checkpoint_Efficient_Base.ckpt\n",
      "463/463 [==============================] - 381s 817ms/step - loss: 0.1340 - tp: 87296.0000 - fp: 32037.0000 - tn: 4822093.0000 - fn: 199726.0000 - accuracy: 0.9549 - precision: 0.7315 - recall: 0.3041 - val_loss: 0.1431 - val_tp: 20256.0000 - val_fp: 7785.0000 - val_tn: 1205747.0000 - val_fn: 51500.0000 - val_accuracy: 0.9539 - val_precision: 0.7224 - val_recall: 0.2823\n"
     ]
    }
   ],
   "source": [
    "history_model_2 = model_2.fit(ds_train_batched, \n",
    "        validation_data =ds_test_batched,\n",
    "        epochs=10,\n",
    "        callbacks=[early_stopping, checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.save(\"../trained_models/IN_SHOP_Models/model_2_efficient_net.h5\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history_model_2.history).to_csv(\"../trained_models/IN_SHOP_Models/model_2_efficient_net_step3.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2 Fine Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import clone_model \n",
    "\n",
    "model_2_fine = clone_model(model_2)\n",
    "model_2_fine.set_weights(model_2.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True name: input_8\n",
      "True name: efficientnetb0\n",
      "True name: global_average_pooling2d_3\n",
      "True name: dense_3\n"
     ]
    }
   ],
   "source": [
    "for layer in model_2_fine.layers: \n",
    "    print(layer.trainable,\"name:\" ,layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'efficientnetb0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ef_net_for_fine = model_2_fine.layers[1]\n",
    "model_2_fine.layers[1].name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ef_net_for_fine.trainable = True  \n",
    "\n",
    "for layer in ef_net_for_fine.layers[:-10]:\n",
    "    layer.trainable = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall')\n",
    "]\n",
    "\n",
    "model_2_fine.compile(optimizer=keras.optimizers.Adam(),\n",
    "              loss=keras.losses.BinaryCrossentropy(), \n",
    "              metrics=METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True block7a_se_squeeze\n",
      "True block7a_se_reshape\n",
      "True block7a_se_reduce\n",
      "True block7a_se_expand\n",
      "True block7a_se_excite\n",
      "True block7a_project_conv\n",
      "True block7a_project_bn\n",
      "True top_conv\n",
      "True top_bn\n",
      "True top_activation\n"
     ]
    }
   ],
   "source": [
    "for layer in ef_net_for_fine.layers[-10:]: \n",
    "    print(layer.trainable, layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x2349d965fa0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# model_2_fine.load_weights(\"checkpoints/in-shop_ds_model2_fine_tune/checkpoint_Efficient_Base.ckpt\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"checkpoints/in-shop_ds_model2_fine_tune_STEP3/checkpoint_Efficient_Base.ckpt\" \n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                         save_weights_only=True,\n",
    "                                                         save_best_only=False,\n",
    "                                                         verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20\n",
      "463/463 [==============================] - ETA: 0s - loss: 0.1437 - tp: 81404.0000 - fp: 38510.0000 - tn: 4815620.0000 - fn: 205618.0000 - accuracy: 0.9525 - precision: 0.6789 - recall: 0.2836\n",
      "Epoch 10: saving model to checkpoints/in-shop_ds_model2_fine_tune_STEP3\\checkpoint_Efficient_Base.ckpt\n",
      "463/463 [==============================] - 683s 1s/step - loss: 0.1437 - tp: 81404.0000 - fp: 38510.0000 - tn: 4815620.0000 - fn: 205618.0000 - accuracy: 0.9525 - precision: 0.6789 - recall: 0.2836 - val_loss: 0.1428 - val_tp: 22207.0000 - val_fp: 9873.0000 - val_tn: 1203659.0000 - val_fn: 49549.0000 - val_accuracy: 0.9538 - val_precision: 0.6922 - val_recall: 0.3095\n",
      "Epoch 11/20\n",
      "463/463 [==============================] - ETA: 0s - loss: 0.1344 - tp: 88316.0000 - fp: 34777.0000 - tn: 4819353.0000 - fn: 198706.0000 - accuracy: 0.9546 - precision: 0.7175 - recall: 0.3077\n",
      "Epoch 11: saving model to checkpoints/in-shop_ds_model2_fine_tune_STEP3\\checkpoint_Efficient_Base.ckpt\n",
      "463/463 [==============================] - 695s 1s/step - loss: 0.1344 - tp: 88316.0000 - fp: 34777.0000 - tn: 4819353.0000 - fn: 198706.0000 - accuracy: 0.9546 - precision: 0.7175 - recall: 0.3077 - val_loss: 0.1427 - val_tp: 22352.0000 - val_fp: 9425.0000 - val_tn: 1204107.0000 - val_fn: 49404.0000 - val_accuracy: 0.9542 - val_precision: 0.7034 - val_recall: 0.3115\n",
      "Epoch 12/20\n",
      "463/463 [==============================] - ETA: 0s - loss: 0.1287 - tp: 93409.0000 - fp: 33435.0000 - tn: 4820695.0000 - fn: 193613.0000 - accuracy: 0.9558 - precision: 0.7364 - recall: 0.3254\n",
      "Epoch 12: saving model to checkpoints/in-shop_ds_model2_fine_tune_STEP3\\checkpoint_Efficient_Base.ckpt\n",
      "463/463 [==============================] - 672s 1s/step - loss: 0.1287 - tp: 93409.0000 - fp: 33435.0000 - tn: 4820695.0000 - fn: 193613.0000 - accuracy: 0.9558 - precision: 0.7364 - recall: 0.3254 - val_loss: 0.1433 - val_tp: 23242.0000 - val_fp: 10334.0000 - val_tn: 1203198.0000 - val_fn: 48514.0000 - val_accuracy: 0.9542 - val_precision: 0.6922 - val_recall: 0.3239\n",
      "Epoch 13/20\n",
      "463/463 [==============================] - ETA: 0s - loss: 0.1240 - tp: 98269.0000 - fp: 32439.0000 - tn: 4821691.0000 - fn: 188753.0000 - accuracy: 0.9570 - precision: 0.7518 - recall: 0.3424\n",
      "Epoch 13: saving model to checkpoints/in-shop_ds_model2_fine_tune_STEP3\\checkpoint_Efficient_Base.ckpt\n",
      "463/463 [==============================] - 656s 1s/step - loss: 0.1240 - tp: 98269.0000 - fp: 32439.0000 - tn: 4821691.0000 - fn: 188753.0000 - accuracy: 0.9570 - precision: 0.7518 - recall: 0.3424 - val_loss: 0.1425 - val_tp: 23764.0000 - val_fp: 10718.0000 - val_tn: 1202814.0000 - val_fn: 47992.0000 - val_accuracy: 0.9543 - val_precision: 0.6892 - val_recall: 0.3312\n",
      "Epoch 14/20\n",
      "463/463 [==============================] - ETA: 0s - loss: 0.1199 - tp: 102546.0000 - fp: 31927.0000 - tn: 4822203.0000 - fn: 184476.0000 - accuracy: 0.9579 - precision: 0.7626 - recall: 0.3573\n",
      "Epoch 14: saving model to checkpoints/in-shop_ds_model2_fine_tune_STEP3\\checkpoint_Efficient_Base.ckpt\n",
      "463/463 [==============================] - 763s 2s/step - loss: 0.1199 - tp: 102546.0000 - fp: 31927.0000 - tn: 4822203.0000 - fn: 184476.0000 - accuracy: 0.9579 - precision: 0.7626 - recall: 0.3573 - val_loss: 0.1417 - val_tp: 23771.0000 - val_fp: 10945.0000 - val_tn: 1202587.0000 - val_fn: 47985.0000 - val_accuracy: 0.9542 - val_precision: 0.6847 - val_recall: 0.3313\n",
      "Epoch 15/20\n",
      "463/463 [==============================] - ETA: 0s - loss: 0.1159 - tp: 107125.0000 - fp: 31421.0000 - tn: 4822709.0000 - fn: 179897.0000 - accuracy: 0.9589 - precision: 0.7732 - recall: 0.3732\n",
      "Epoch 15: saving model to checkpoints/in-shop_ds_model2_fine_tune_STEP3\\checkpoint_Efficient_Base.ckpt\n",
      "463/463 [==============================] - 718s 2s/step - loss: 0.1159 - tp: 107125.0000 - fp: 31421.0000 - tn: 4822709.0000 - fn: 179897.0000 - accuracy: 0.9589 - precision: 0.7732 - recall: 0.3732 - val_loss: 0.1411 - val_tp: 24341.0000 - val_fp: 11483.0000 - val_tn: 1202049.0000 - val_fn: 47415.0000 - val_accuracy: 0.9542 - val_precision: 0.6795 - val_recall: 0.3392\n",
      "Epoch 16/20\n",
      "463/463 [==============================] - ETA: 0s - loss: 0.1123 - tp: 111488.0000 - fp: 31088.0000 - tn: 4823042.0000 - fn: 175534.0000 - accuracy: 0.9598 - precision: 0.7820 - recall: 0.3884\n",
      "Epoch 16: saving model to checkpoints/in-shop_ds_model2_fine_tune_STEP3\\checkpoint_Efficient_Base.ckpt\n",
      "463/463 [==============================] - 662s 1s/step - loss: 0.1123 - tp: 111488.0000 - fp: 31088.0000 - tn: 4823042.0000 - fn: 175534.0000 - accuracy: 0.9598 - precision: 0.7820 - recall: 0.3884 - val_loss: 0.1411 - val_tp: 24461.0000 - val_fp: 11545.0000 - val_tn: 1201987.0000 - val_fn: 47295.0000 - val_accuracy: 0.9542 - val_precision: 0.6794 - val_recall: 0.3409\n",
      "Epoch 17/20\n",
      "463/463 [==============================] - ETA: 0s - loss: 0.1087 - tp: 116011.0000 - fp: 30822.0000 - tn: 4823308.0000 - fn: 171011.0000 - accuracy: 0.9607 - precision: 0.7901 - recall: 0.4042\n",
      "Epoch 17: saving model to checkpoints/in-shop_ds_model2_fine_tune_STEP3\\checkpoint_Efficient_Base.ckpt\n",
      "463/463 [==============================] - 657s 1s/step - loss: 0.1087 - tp: 116011.0000 - fp: 30822.0000 - tn: 4823308.0000 - fn: 171011.0000 - accuracy: 0.9607 - precision: 0.7901 - recall: 0.4042 - val_loss: 0.1433 - val_tp: 23888.0000 - val_fp: 11460.0000 - val_tn: 1202072.0000 - val_fn: 47868.0000 - val_accuracy: 0.9538 - val_precision: 0.6758 - val_recall: 0.3329\n",
      "Epoch 18/20\n",
      "463/463 [==============================] - ETA: 0s - loss: 0.1051 - tp: 120556.0000 - fp: 30267.0000 - tn: 4823863.0000 - fn: 166466.0000 - accuracy: 0.9617 - precision: 0.7993 - recall: 0.4200\n",
      "Epoch 18: saving model to checkpoints/in-shop_ds_model2_fine_tune_STEP3\\checkpoint_Efficient_Base.ckpt\n",
      "463/463 [==============================] - 655s 1s/step - loss: 0.1051 - tp: 120556.0000 - fp: 30267.0000 - tn: 4823863.0000 - fn: 166466.0000 - accuracy: 0.9617 - precision: 0.7993 - recall: 0.4200 - val_loss: 0.1476 - val_tp: 24407.0000 - val_fp: 13945.0000 - val_tn: 1199587.0000 - val_fn: 47349.0000 - val_accuracy: 0.9523 - val_precision: 0.6364 - val_recall: 0.3401\n",
      "Epoch 19/20\n",
      "463/463 [==============================] - ETA: 0s - loss: 0.1020 - tp: 124877.0000 - fp: 30095.0000 - tn: 4824035.0000 - fn: 162145.0000 - accuracy: 0.9626 - precision: 0.8058 - recall: 0.4351\n",
      "Epoch 19: saving model to checkpoints/in-shop_ds_model2_fine_tune_STEP3\\checkpoint_Efficient_Base.ckpt\n",
      "463/463 [==============================] - 657s 1s/step - loss: 0.1020 - tp: 124877.0000 - fp: 30095.0000 - tn: 4824035.0000 - fn: 162145.0000 - accuracy: 0.9626 - precision: 0.8058 - recall: 0.4351 - val_loss: 0.1494 - val_tp: 24692.0000 - val_fp: 15471.0000 - val_tn: 1198061.0000 - val_fn: 47064.0000 - val_accuracy: 0.9513 - val_precision: 0.6148 - val_recall: 0.3441\n",
      "Epoch 20/20\n",
      "463/463 [==============================] - ETA: 0s - loss: 0.0989 - tp: 129592.0000 - fp: 29832.0000 - tn: 4824298.0000 - fn: 157430.0000 - accuracy: 0.9636 - precision: 0.8129 - recall: 0.4515\n",
      "Epoch 20: saving model to checkpoints/in-shop_ds_model2_fine_tune_STEP3\\checkpoint_Efficient_Base.ckpt\n",
      "463/463 [==============================] - 643s 1s/step - loss: 0.0989 - tp: 129592.0000 - fp: 29832.0000 - tn: 4824298.0000 - fn: 157430.0000 - accuracy: 0.9636 - precision: 0.8129 - recall: 0.4515 - val_loss: 0.1501 - val_tp: 24570.0000 - val_fp: 15076.0000 - val_tn: 1198456.0000 - val_fn: 47186.0000 - val_accuracy: 0.9516 - val_precision: 0.6197 - val_recall: 0.3424\n"
     ]
    }
   ],
   "source": [
    "history_model_2_fine = model_2_fine.fit(ds_train_batched, \n",
    "        validation_data =ds_test_batched,\n",
    "        epochs=20, \n",
    "        initial_epoch=history_model_2.epoch[-1], # start from previous last epoch \n",
    "        callbacks=[early_stopping, checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2_fine.save(\"../trained_models/IN_SHOP_Models/model_2_efficient_net_fine_tune_STEP_3_OverFitting.h5\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history_model_2_fine.history).to_csv(\"../trained_models/IN_SHOP_Models/model_2_efficient_net_fine_tune_STEP_3_OverFitting.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>tp</th>\n",
       "      <th>fp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fn</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_tp</th>\n",
       "      <th>val_fp</th>\n",
       "      <th>val_tn</th>\n",
       "      <th>val_fn</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_precision</th>\n",
       "      <th>val_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.143684</td>\n",
       "      <td>81404.0</td>\n",
       "      <td>38510.0</td>\n",
       "      <td>4815620.0</td>\n",
       "      <td>205618.0</td>\n",
       "      <td>0.952515</td>\n",
       "      <td>0.678853</td>\n",
       "      <td>0.283616</td>\n",
       "      <td>0.142841</td>\n",
       "      <td>22207.0</td>\n",
       "      <td>9873.0</td>\n",
       "      <td>1203659.0</td>\n",
       "      <td>49549.0</td>\n",
       "      <td>0.953768</td>\n",
       "      <td>0.692238</td>\n",
       "      <td>0.309479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.134357</td>\n",
       "      <td>88316.0</td>\n",
       "      <td>34777.0</td>\n",
       "      <td>4819353.0</td>\n",
       "      <td>198706.0</td>\n",
       "      <td>0.954585</td>\n",
       "      <td>0.717474</td>\n",
       "      <td>0.307698</td>\n",
       "      <td>0.142742</td>\n",
       "      <td>22352.0</td>\n",
       "      <td>9425.0</td>\n",
       "      <td>1204107.0</td>\n",
       "      <td>49404.0</td>\n",
       "      <td>0.954229</td>\n",
       "      <td>0.703402</td>\n",
       "      <td>0.311500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.128667</td>\n",
       "      <td>93409.0</td>\n",
       "      <td>33435.0</td>\n",
       "      <td>4820695.0</td>\n",
       "      <td>193613.0</td>\n",
       "      <td>0.955837</td>\n",
       "      <td>0.736408</td>\n",
       "      <td>0.325442</td>\n",
       "      <td>0.143303</td>\n",
       "      <td>23242.0</td>\n",
       "      <td>10334.0</td>\n",
       "      <td>1203198.0</td>\n",
       "      <td>48514.0</td>\n",
       "      <td>0.954214</td>\n",
       "      <td>0.692221</td>\n",
       "      <td>0.323903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.124024</td>\n",
       "      <td>98269.0</td>\n",
       "      <td>32439.0</td>\n",
       "      <td>4821691.0</td>\n",
       "      <td>188753.0</td>\n",
       "      <td>0.956976</td>\n",
       "      <td>0.751821</td>\n",
       "      <td>0.342374</td>\n",
       "      <td>0.142470</td>\n",
       "      <td>23764.0</td>\n",
       "      <td>10718.0</td>\n",
       "      <td>1202814.0</td>\n",
       "      <td>47992.0</td>\n",
       "      <td>0.954322</td>\n",
       "      <td>0.689171</td>\n",
       "      <td>0.331178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.119882</td>\n",
       "      <td>102546.0</td>\n",
       "      <td>31927.0</td>\n",
       "      <td>4822203.0</td>\n",
       "      <td>184476.0</td>\n",
       "      <td>0.957908</td>\n",
       "      <td>0.762577</td>\n",
       "      <td>0.357276</td>\n",
       "      <td>0.141750</td>\n",
       "      <td>23771.0</td>\n",
       "      <td>10945.0</td>\n",
       "      <td>1202587.0</td>\n",
       "      <td>47985.0</td>\n",
       "      <td>0.954150</td>\n",
       "      <td>0.684727</td>\n",
       "      <td>0.331275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.115948</td>\n",
       "      <td>107125.0</td>\n",
       "      <td>31421.0</td>\n",
       "      <td>4822709.0</td>\n",
       "      <td>179897.0</td>\n",
       "      <td>0.958897</td>\n",
       "      <td>0.773209</td>\n",
       "      <td>0.373229</td>\n",
       "      <td>0.141099</td>\n",
       "      <td>24341.0</td>\n",
       "      <td>11483.0</td>\n",
       "      <td>1202049.0</td>\n",
       "      <td>47415.0</td>\n",
       "      <td>0.954175</td>\n",
       "      <td>0.679461</td>\n",
       "      <td>0.339219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.112315</td>\n",
       "      <td>111488.0</td>\n",
       "      <td>31088.0</td>\n",
       "      <td>4823042.0</td>\n",
       "      <td>175534.0</td>\n",
       "      <td>0.959810</td>\n",
       "      <td>0.781955</td>\n",
       "      <td>0.388430</td>\n",
       "      <td>0.141108</td>\n",
       "      <td>24461.0</td>\n",
       "      <td>11545.0</td>\n",
       "      <td>1201987.0</td>\n",
       "      <td>47295.0</td>\n",
       "      <td>0.954220</td>\n",
       "      <td>0.679359</td>\n",
       "      <td>0.340891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.108673</td>\n",
       "      <td>116011.0</td>\n",
       "      <td>30822.0</td>\n",
       "      <td>4823308.0</td>\n",
       "      <td>171011.0</td>\n",
       "      <td>0.960742</td>\n",
       "      <td>0.790088</td>\n",
       "      <td>0.404189</td>\n",
       "      <td>0.143254</td>\n",
       "      <td>23888.0</td>\n",
       "      <td>11460.0</td>\n",
       "      <td>1202072.0</td>\n",
       "      <td>47868.0</td>\n",
       "      <td>0.953841</td>\n",
       "      <td>0.675795</td>\n",
       "      <td>0.332906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.105093</td>\n",
       "      <td>120556.0</td>\n",
       "      <td>30267.0</td>\n",
       "      <td>4823863.0</td>\n",
       "      <td>166466.0</td>\n",
       "      <td>0.961734</td>\n",
       "      <td>0.799321</td>\n",
       "      <td>0.420024</td>\n",
       "      <td>0.147587</td>\n",
       "      <td>24407.0</td>\n",
       "      <td>13945.0</td>\n",
       "      <td>1199587.0</td>\n",
       "      <td>47349.0</td>\n",
       "      <td>0.952311</td>\n",
       "      <td>0.636394</td>\n",
       "      <td>0.340139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.102033</td>\n",
       "      <td>124877.0</td>\n",
       "      <td>30095.0</td>\n",
       "      <td>4824035.0</td>\n",
       "      <td>162145.0</td>\n",
       "      <td>0.962608</td>\n",
       "      <td>0.805804</td>\n",
       "      <td>0.435078</td>\n",
       "      <td>0.149421</td>\n",
       "      <td>24692.0</td>\n",
       "      <td>15471.0</td>\n",
       "      <td>1198061.0</td>\n",
       "      <td>47064.0</td>\n",
       "      <td>0.951346</td>\n",
       "      <td>0.614795</td>\n",
       "      <td>0.344111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.098880</td>\n",
       "      <td>129592.0</td>\n",
       "      <td>29832.0</td>\n",
       "      <td>4824298.0</td>\n",
       "      <td>157430.0</td>\n",
       "      <td>0.963576</td>\n",
       "      <td>0.812876</td>\n",
       "      <td>0.451505</td>\n",
       "      <td>0.150148</td>\n",
       "      <td>24570.0</td>\n",
       "      <td>15076.0</td>\n",
       "      <td>1198456.0</td>\n",
       "      <td>47186.0</td>\n",
       "      <td>0.951558</td>\n",
       "      <td>0.619735</td>\n",
       "      <td>0.342410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss        tp       fp         tn        fn  accuracy  precision  \\\n",
       "0   0.143684   81404.0  38510.0  4815620.0  205618.0  0.952515   0.678853   \n",
       "1   0.134357   88316.0  34777.0  4819353.0  198706.0  0.954585   0.717474   \n",
       "2   0.128667   93409.0  33435.0  4820695.0  193613.0  0.955837   0.736408   \n",
       "3   0.124024   98269.0  32439.0  4821691.0  188753.0  0.956976   0.751821   \n",
       "4   0.119882  102546.0  31927.0  4822203.0  184476.0  0.957908   0.762577   \n",
       "5   0.115948  107125.0  31421.0  4822709.0  179897.0  0.958897   0.773209   \n",
       "6   0.112315  111488.0  31088.0  4823042.0  175534.0  0.959810   0.781955   \n",
       "7   0.108673  116011.0  30822.0  4823308.0  171011.0  0.960742   0.790088   \n",
       "8   0.105093  120556.0  30267.0  4823863.0  166466.0  0.961734   0.799321   \n",
       "9   0.102033  124877.0  30095.0  4824035.0  162145.0  0.962608   0.805804   \n",
       "10  0.098880  129592.0  29832.0  4824298.0  157430.0  0.963576   0.812876   \n",
       "\n",
       "      recall  val_loss   val_tp   val_fp     val_tn   val_fn  val_accuracy  \\\n",
       "0   0.283616  0.142841  22207.0   9873.0  1203659.0  49549.0      0.953768   \n",
       "1   0.307698  0.142742  22352.0   9425.0  1204107.0  49404.0      0.954229   \n",
       "2   0.325442  0.143303  23242.0  10334.0  1203198.0  48514.0      0.954214   \n",
       "3   0.342374  0.142470  23764.0  10718.0  1202814.0  47992.0      0.954322   \n",
       "4   0.357276  0.141750  23771.0  10945.0  1202587.0  47985.0      0.954150   \n",
       "5   0.373229  0.141099  24341.0  11483.0  1202049.0  47415.0      0.954175   \n",
       "6   0.388430  0.141108  24461.0  11545.0  1201987.0  47295.0      0.954220   \n",
       "7   0.404189  0.143254  23888.0  11460.0  1202072.0  47868.0      0.953841   \n",
       "8   0.420024  0.147587  24407.0  13945.0  1199587.0  47349.0      0.952311   \n",
       "9   0.435078  0.149421  24692.0  15471.0  1198061.0  47064.0      0.951346   \n",
       "10  0.451505  0.150148  24570.0  15076.0  1198456.0  47186.0      0.951558   \n",
       "\n",
       "    val_precision  val_recall  \n",
       "0        0.692238    0.309479  \n",
       "1        0.703402    0.311500  \n",
       "2        0.692221    0.323903  \n",
       "3        0.689171    0.331178  \n",
       "4        0.684727    0.331275  \n",
       "5        0.679461    0.339219  \n",
       "6        0.679359    0.340891  \n",
       "7        0.675795    0.332906  \n",
       "8        0.636394    0.340139  \n",
       "9        0.614795    0.344111  \n",
       "10       0.619735    0.342410  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history_model_2_fine.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2 Fine Tune: Partitioned Learning Rate and MultiOptimizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(len(ef_net_for_fine.layers) / 3)\n",
    "\n",
    "optimizers = [\n",
    "    keras.optimizers.Adam(), # for layer [0] and last layer \n",
    "    tf.keras.optimizers.Adam(learning_rate=1e-6), # ef net [0 to 80] \n",
    "    tf.keras.optimizers.Adam(learning_rate=1e-4), # ef net [80 to 160] \n",
    "    tf.keras.optimizers.Adam(learning_rate=1e-2), # # ef net [160 to :ef net last] \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers_and_layers = [\n",
    "    (optimizers[0], model_2_fine.layers[0]), \n",
    "    (optimizers[1], ef_net_for_fine.layers[0:80]), \n",
    "    (optimizers[2], ef_net_for_fine.layers[80:160]),\n",
    "    (optimizers[3], ef_net_for_fine.layers[160:]),\n",
    "    (optimizers[0], model_2_fine.layers[-1]),   \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow-addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_addons as tfa\n",
    "optimizer = tfa.optimizers.MultiOptimizer(optimizers_and_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20\n",
      "463/463 [==============================] - ETA: 0s - loss: 0.1640 - tp: 62854.0000 - fp: 34782.0000 - tn: 4819348.0000 - fn: 224168.0000 - accuracy: 0.9496 - precision: 0.6438 - recall: 0.2190\n",
      "Epoch 10: saving model to checkpoints/in-shop_ds_model2_fine_tune_STEP3\\checkpoint_Efficient_multi_optimizer.ckpt\n",
      "463/463 [==============================] - 923s 2s/step - loss: 0.1640 - tp: 62854.0000 - fp: 34782.0000 - tn: 4819348.0000 - fn: 224168.0000 - accuracy: 0.9496 - precision: 0.6438 - recall: 0.2190 - val_loss: 0.1847 - val_tp: 23622.0000 - val_fp: 26388.0000 - val_tn: 1187144.0000 - val_fn: 48134.0000 - val_accuracy: 0.9420 - val_precision: 0.4723 - val_recall: 0.3292\n",
      "Epoch 11/20\n",
      "463/463 [==============================] - ETA: 0s - loss: 0.1522 - tp: 72100.0000 - fp: 31394.0000 - tn: 4822736.0000 - fn: 214922.0000 - accuracy: 0.9521 - precision: 0.6967 - recall: 0.2512\n",
      "Epoch 11: saving model to checkpoints/in-shop_ds_model2_fine_tune_STEP3\\checkpoint_Efficient_multi_optimizer.ckpt\n",
      "463/463 [==============================] - 923s 2s/step - loss: 0.1522 - tp: 72100.0000 - fp: 31394.0000 - tn: 4822736.0000 - fn: 214922.0000 - accuracy: 0.9521 - precision: 0.6967 - recall: 0.2512 - val_loss: 0.1616 - val_tp: 22868.0000 - val_fp: 16983.0000 - val_tn: 1196549.0000 - val_fn: 48888.0000 - val_accuracy: 0.9488 - val_precision: 0.5738 - val_recall: 0.3187\n",
      "Epoch 12/20\n",
      "463/463 [==============================] - ETA: 0s - loss: 0.1472 - tp: 77463.0000 - fp: 31800.0000 - tn: 4822330.0000 - fn: 209559.0000 - accuracy: 0.9531 - precision: 0.7090 - recall: 0.2699\n",
      "Epoch 12: saving model to checkpoints/in-shop_ds_model2_fine_tune_STEP3\\checkpoint_Efficient_multi_optimizer.ckpt\n",
      "463/463 [==============================] - 960s 2s/step - loss: 0.1472 - tp: 77463.0000 - fp: 31800.0000 - tn: 4822330.0000 - fn: 209559.0000 - accuracy: 0.9531 - precision: 0.7090 - recall: 0.2699 - val_loss: 0.1510 - val_tp: 20596.0000 - val_fp: 10242.0000 - val_tn: 1203290.0000 - val_fn: 51160.0000 - val_accuracy: 0.9522 - val_precision: 0.6679 - val_recall: 0.2870\n",
      "Epoch 13/20\n",
      "463/463 [==============================] - ETA: 0s - loss: 0.1436 - tp: 81525.0000 - fp: 32170.0000 - tn: 4821960.0000 - fn: 205497.0000 - accuracy: 0.9538 - precision: 0.7171 - recall: 0.2840\n",
      "Epoch 13: saving model to checkpoints/in-shop_ds_model2_fine_tune_STEP3\\checkpoint_Efficient_multi_optimizer.ckpt\n",
      "463/463 [==============================] - 1033s 2s/step - loss: 0.1436 - tp: 81525.0000 - fp: 32170.0000 - tn: 4821960.0000 - fn: 205497.0000 - accuracy: 0.9538 - precision: 0.7171 - recall: 0.2840 - val_loss: 0.1518 - val_tp: 20872.0000 - val_fp: 10587.0000 - val_tn: 1202945.0000 - val_fn: 50884.0000 - val_accuracy: 0.9522 - val_precision: 0.6635 - val_recall: 0.2909\n",
      "Epoch 14/20\n",
      "463/463 [==============================] - ETA: 0s - loss: 0.1407 - tp: 84860.0000 - fp: 32149.0000 - tn: 4821981.0000 - fn: 202162.0000 - accuracy: 0.9544 - precision: 0.7252 - recall: 0.2957\n",
      "Epoch 14: saving model to checkpoints/in-shop_ds_model2_fine_tune_STEP3\\checkpoint_Efficient_multi_optimizer.ckpt\n",
      "463/463 [==============================] - 986s 2s/step - loss: 0.1407 - tp: 84860.0000 - fp: 32149.0000 - tn: 4821981.0000 - fn: 202162.0000 - accuracy: 0.9544 - precision: 0.7252 - recall: 0.2957 - val_loss: 0.1521 - val_tp: 19638.0000 - val_fp: 8253.0000 - val_tn: 1205279.0000 - val_fn: 52118.0000 - val_accuracy: 0.9530 - val_precision: 0.7041 - val_recall: 0.2737\n",
      "Epoch 15/20\n",
      "463/463 [==============================] - ETA: 0s - loss: 0.1380 - tp: 87954.0000 - fp: 32270.0000 - tn: 4821860.0000 - fn: 199068.0000 - accuracy: 0.9550 - precision: 0.7316 - recall: 0.3064\n",
      "Epoch 15: saving model to checkpoints/in-shop_ds_model2_fine_tune_STEP3\\checkpoint_Efficient_multi_optimizer.ckpt\n",
      "463/463 [==============================] - 920s 2s/step - loss: 0.1380 - tp: 87954.0000 - fp: 32270.0000 - tn: 4821860.0000 - fn: 199068.0000 - accuracy: 0.9550 - precision: 0.7316 - recall: 0.3064 - val_loss: 0.1495 - val_tp: 18706.0000 - val_fp: 7240.0000 - val_tn: 1206292.0000 - val_fn: 53050.0000 - val_accuracy: 0.9531 - val_precision: 0.7210 - val_recall: 0.2607\n",
      "Epoch 16/20\n",
      "463/463 [==============================] - ETA: 0s - loss: 0.1356 - tp: 90566.0000 - fp: 32054.0000 - tn: 4822076.0000 - fn: 196456.0000 - accuracy: 0.9556 - precision: 0.7386 - recall: 0.3155\n",
      "Epoch 16: saving model to checkpoints/in-shop_ds_model2_fine_tune_STEP3\\checkpoint_Efficient_multi_optimizer.ckpt\n",
      "463/463 [==============================] - 891s 2s/step - loss: 0.1356 - tp: 90566.0000 - fp: 32054.0000 - tn: 4822076.0000 - fn: 196456.0000 - accuracy: 0.9556 - precision: 0.7386 - recall: 0.3155 - val_loss: 0.1498 - val_tp: 17895.0000 - val_fp: 6485.0000 - val_tn: 1207047.0000 - val_fn: 53861.0000 - val_accuracy: 0.9530 - val_precision: 0.7340 - val_recall: 0.2494\n",
      "Epoch 17/20\n",
      "463/463 [==============================] - ETA: 0s - loss: 0.1332 - tp: 93211.0000 - fp: 32287.0000 - tn: 4821843.0000 - fn: 193811.0000 - accuracy: 0.9560 - precision: 0.7427 - recall: 0.3248\n",
      "Epoch 17: saving model to checkpoints/in-shop_ds_model2_fine_tune_STEP3\\checkpoint_Efficient_multi_optimizer.ckpt\n",
      "463/463 [==============================] - 885s 2s/step - loss: 0.1332 - tp: 93211.0000 - fp: 32287.0000 - tn: 4821843.0000 - fn: 193811.0000 - accuracy: 0.9560 - precision: 0.7427 - recall: 0.3248 - val_loss: 0.1514 - val_tp: 17940.0000 - val_fp: 7053.0000 - val_tn: 1206479.0000 - val_fn: 53816.0000 - val_accuracy: 0.9526 - val_precision: 0.7178 - val_recall: 0.2500\n",
      "Epoch 18/20\n",
      "463/463 [==============================] - ETA: 0s - loss: 0.1310 - tp: 95398.0000 - fp: 32008.0000 - tn: 4822122.0000 - fn: 191624.0000 - accuracy: 0.9565 - precision: 0.7488 - recall: 0.3324\n",
      "Epoch 18: saving model to checkpoints/in-shop_ds_model2_fine_tune_STEP3\\checkpoint_Efficient_multi_optimizer.ckpt\n",
      "463/463 [==============================] - 885s 2s/step - loss: 0.1310 - tp: 95398.0000 - fp: 32008.0000 - tn: 4822122.0000 - fn: 191624.0000 - accuracy: 0.9565 - precision: 0.7488 - recall: 0.3324 - val_loss: 0.1500 - val_tp: 18722.0000 - val_fp: 7389.0000 - val_tn: 1206143.0000 - val_fn: 53034.0000 - val_accuracy: 0.9530 - val_precision: 0.7170 - val_recall: 0.2609\n",
      "Epoch 19/20\n",
      "463/463 [==============================] - ETA: 0s - loss: 0.1287 - tp: 97957.0000 - fp: 32003.0000 - tn: 4822127.0000 - fn: 189065.0000 - accuracy: 0.9570 - precision: 0.7537 - recall: 0.3413\n",
      "Epoch 19: saving model to checkpoints/in-shop_ds_model2_fine_tune_STEP3\\checkpoint_Efficient_multi_optimizer.ckpt\n",
      "463/463 [==============================] - 877s 2s/step - loss: 0.1287 - tp: 97957.0000 - fp: 32003.0000 - tn: 4822127.0000 - fn: 189065.0000 - accuracy: 0.9570 - precision: 0.7537 - recall: 0.3413 - val_loss: 0.1483 - val_tp: 19931.0000 - val_fp: 8035.0000 - val_tn: 1205497.0000 - val_fn: 51825.0000 - val_accuracy: 0.9534 - val_precision: 0.7127 - val_recall: 0.2778\n",
      "Epoch 20/20\n",
      "463/463 [==============================] - ETA: 0s - loss: 0.1265 - tp: 100128.0000 - fp: 31898.0000 - tn: 4822232.0000 - fn: 186894.0000 - accuracy: 0.9574 - precision: 0.7584 - recall: 0.3489\n",
      "Epoch 20: saving model to checkpoints/in-shop_ds_model2_fine_tune_STEP3\\checkpoint_Efficient_multi_optimizer.ckpt\n",
      "463/463 [==============================] - 854s 2s/step - loss: 0.1265 - tp: 100128.0000 - fp: 31898.0000 - tn: 4822232.0000 - fn: 186894.0000 - accuracy: 0.9574 - precision: 0.7584 - recall: 0.3489 - val_loss: 0.1503 - val_tp: 21521.0000 - val_fp: 10544.0000 - val_tn: 1202988.0000 - val_fn: 50235.0000 - val_accuracy: 0.9527 - val_precision: 0.6712 - val_recall: 0.2999\n"
     ]
    }
   ],
   "source": [
    "model_2_fine_multi_optimizer = clone_model(model_2)\n",
    "model_2_fine_multi_optimizer.set_weights(model_2.get_weights())\n",
    "ef_net_for_fine = model_2_fine_multi_optimizer.layers[1]\n",
    "\n",
    "\n",
    "ef_net_for_fine.trainable = True  \n",
    "for layer in ef_net_for_fine.layers[:-20]:\n",
    "    layer.trainable = False \n",
    "\n",
    "METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall')\n",
    "]\n",
    "\n",
    "model_2_fine_multi_optimizer.compile(optimizer=optimizer,\n",
    "                    loss=keras.losses.BinaryCrossentropy(), \n",
    "                    metrics=METRICS)\n",
    "\n",
    "checkpoint_path = \"checkpoints/in-shop_ds_model2_fine_tune_STEP3/checkpoint_Efficient_multi_optimizer.ckpt\" \n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                         save_weights_only=True,\n",
    "                                                         save_best_only=False,\n",
    "                                                         verbose=1)\n",
    "\n",
    "history_model_2_fine_multi_optimizer = model_2_fine_multi_optimizer.fit(ds_train_batched, \n",
    "        validation_data =ds_test_batched,\n",
    "        epochs=20, \n",
    "        initial_epoch=history_model_2.epoch[-1], # start from previous last epoch \n",
    "        callbacks=[early_stopping, checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>tp</th>\n",
       "      <th>fp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fn</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_tp</th>\n",
       "      <th>val_fp</th>\n",
       "      <th>val_tn</th>\n",
       "      <th>val_fn</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_precision</th>\n",
       "      <th>val_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.164045</td>\n",
       "      <td>62854.0</td>\n",
       "      <td>34782.0</td>\n",
       "      <td>4819348.0</td>\n",
       "      <td>224168.0</td>\n",
       "      <td>0.949632</td>\n",
       "      <td>0.643758</td>\n",
       "      <td>0.218987</td>\n",
       "      <td>0.184724</td>\n",
       "      <td>23622.0</td>\n",
       "      <td>26388.0</td>\n",
       "      <td>1187144.0</td>\n",
       "      <td>48134.0</td>\n",
       "      <td>0.942019</td>\n",
       "      <td>0.472346</td>\n",
       "      <td>0.329199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.152166</td>\n",
       "      <td>72100.0</td>\n",
       "      <td>31394.0</td>\n",
       "      <td>4822736.0</td>\n",
       "      <td>214922.0</td>\n",
       "      <td>0.952089</td>\n",
       "      <td>0.696659</td>\n",
       "      <td>0.251200</td>\n",
       "      <td>0.161577</td>\n",
       "      <td>22868.0</td>\n",
       "      <td>16983.0</td>\n",
       "      <td>1196549.0</td>\n",
       "      <td>48888.0</td>\n",
       "      <td>0.948750</td>\n",
       "      <td>0.573838</td>\n",
       "      <td>0.318691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.147187</td>\n",
       "      <td>77463.0</td>\n",
       "      <td>31800.0</td>\n",
       "      <td>4822330.0</td>\n",
       "      <td>209559.0</td>\n",
       "      <td>0.953054</td>\n",
       "      <td>0.708959</td>\n",
       "      <td>0.269885</td>\n",
       "      <td>0.150965</td>\n",
       "      <td>20596.0</td>\n",
       "      <td>10242.0</td>\n",
       "      <td>1203290.0</td>\n",
       "      <td>51160.0</td>\n",
       "      <td>0.952227</td>\n",
       "      <td>0.667877</td>\n",
       "      <td>0.287028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.143618</td>\n",
       "      <td>81525.0</td>\n",
       "      <td>32170.0</td>\n",
       "      <td>4821960.0</td>\n",
       "      <td>205497.0</td>\n",
       "      <td>0.953772</td>\n",
       "      <td>0.717050</td>\n",
       "      <td>0.284037</td>\n",
       "      <td>0.151777</td>\n",
       "      <td>20872.0</td>\n",
       "      <td>10587.0</td>\n",
       "      <td>1202945.0</td>\n",
       "      <td>50884.0</td>\n",
       "      <td>0.952173</td>\n",
       "      <td>0.663467</td>\n",
       "      <td>0.290875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.140713</td>\n",
       "      <td>84860.0</td>\n",
       "      <td>32149.0</td>\n",
       "      <td>4821981.0</td>\n",
       "      <td>202162.0</td>\n",
       "      <td>0.954424</td>\n",
       "      <td>0.725243</td>\n",
       "      <td>0.295657</td>\n",
       "      <td>0.152079</td>\n",
       "      <td>19638.0</td>\n",
       "      <td>8253.0</td>\n",
       "      <td>1205279.0</td>\n",
       "      <td>52118.0</td>\n",
       "      <td>0.953029</td>\n",
       "      <td>0.704098</td>\n",
       "      <td>0.273677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.137965</td>\n",
       "      <td>87954.0</td>\n",
       "      <td>32270.0</td>\n",
       "      <td>4821860.0</td>\n",
       "      <td>199068.0</td>\n",
       "      <td>0.955003</td>\n",
       "      <td>0.731584</td>\n",
       "      <td>0.306436</td>\n",
       "      <td>0.149519</td>\n",
       "      <td>18706.0</td>\n",
       "      <td>7240.0</td>\n",
       "      <td>1206292.0</td>\n",
       "      <td>53050.0</td>\n",
       "      <td>0.953092</td>\n",
       "      <td>0.720959</td>\n",
       "      <td>0.260689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.135585</td>\n",
       "      <td>90566.0</td>\n",
       "      <td>32054.0</td>\n",
       "      <td>4822076.0</td>\n",
       "      <td>196456.0</td>\n",
       "      <td>0.955553</td>\n",
       "      <td>0.738591</td>\n",
       "      <td>0.315537</td>\n",
       "      <td>0.149828</td>\n",
       "      <td>17895.0</td>\n",
       "      <td>6485.0</td>\n",
       "      <td>1207047.0</td>\n",
       "      <td>53861.0</td>\n",
       "      <td>0.953049</td>\n",
       "      <td>0.734003</td>\n",
       "      <td>0.249387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.133192</td>\n",
       "      <td>93211.0</td>\n",
       "      <td>32287.0</td>\n",
       "      <td>4821843.0</td>\n",
       "      <td>193811.0</td>\n",
       "      <td>0.956022</td>\n",
       "      <td>0.742729</td>\n",
       "      <td>0.324752</td>\n",
       "      <td>0.151381</td>\n",
       "      <td>17940.0</td>\n",
       "      <td>7053.0</td>\n",
       "      <td>1206479.0</td>\n",
       "      <td>53816.0</td>\n",
       "      <td>0.952642</td>\n",
       "      <td>0.717801</td>\n",
       "      <td>0.250014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.131001</td>\n",
       "      <td>95398.0</td>\n",
       "      <td>32008.0</td>\n",
       "      <td>4822122.0</td>\n",
       "      <td>191624.0</td>\n",
       "      <td>0.956502</td>\n",
       "      <td>0.748772</td>\n",
       "      <td>0.332372</td>\n",
       "      <td>0.149976</td>\n",
       "      <td>18722.0</td>\n",
       "      <td>7389.0</td>\n",
       "      <td>1206143.0</td>\n",
       "      <td>53034.0</td>\n",
       "      <td>0.952989</td>\n",
       "      <td>0.717016</td>\n",
       "      <td>0.260912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.128652</td>\n",
       "      <td>97957.0</td>\n",
       "      <td>32003.0</td>\n",
       "      <td>4822127.0</td>\n",
       "      <td>189065.0</td>\n",
       "      <td>0.957000</td>\n",
       "      <td>0.753747</td>\n",
       "      <td>0.341287</td>\n",
       "      <td>0.148263</td>\n",
       "      <td>19931.0</td>\n",
       "      <td>8035.0</td>\n",
       "      <td>1205497.0</td>\n",
       "      <td>51825.0</td>\n",
       "      <td>0.953427</td>\n",
       "      <td>0.712687</td>\n",
       "      <td>0.277761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.126509</td>\n",
       "      <td>100128.0</td>\n",
       "      <td>31898.0</td>\n",
       "      <td>4822232.0</td>\n",
       "      <td>186894.0</td>\n",
       "      <td>0.957443</td>\n",
       "      <td>0.758396</td>\n",
       "      <td>0.348851</td>\n",
       "      <td>0.150312</td>\n",
       "      <td>21521.0</td>\n",
       "      <td>10544.0</td>\n",
       "      <td>1202988.0</td>\n",
       "      <td>50235.0</td>\n",
       "      <td>0.952712</td>\n",
       "      <td>0.671168</td>\n",
       "      <td>0.299919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss        tp       fp         tn        fn  accuracy  precision  \\\n",
       "0   0.164045   62854.0  34782.0  4819348.0  224168.0  0.949632   0.643758   \n",
       "1   0.152166   72100.0  31394.0  4822736.0  214922.0  0.952089   0.696659   \n",
       "2   0.147187   77463.0  31800.0  4822330.0  209559.0  0.953054   0.708959   \n",
       "3   0.143618   81525.0  32170.0  4821960.0  205497.0  0.953772   0.717050   \n",
       "4   0.140713   84860.0  32149.0  4821981.0  202162.0  0.954424   0.725243   \n",
       "5   0.137965   87954.0  32270.0  4821860.0  199068.0  0.955003   0.731584   \n",
       "6   0.135585   90566.0  32054.0  4822076.0  196456.0  0.955553   0.738591   \n",
       "7   0.133192   93211.0  32287.0  4821843.0  193811.0  0.956022   0.742729   \n",
       "8   0.131001   95398.0  32008.0  4822122.0  191624.0  0.956502   0.748772   \n",
       "9   0.128652   97957.0  32003.0  4822127.0  189065.0  0.957000   0.753747   \n",
       "10  0.126509  100128.0  31898.0  4822232.0  186894.0  0.957443   0.758396   \n",
       "\n",
       "      recall  val_loss   val_tp   val_fp     val_tn   val_fn  val_accuracy  \\\n",
       "0   0.218987  0.184724  23622.0  26388.0  1187144.0  48134.0      0.942019   \n",
       "1   0.251200  0.161577  22868.0  16983.0  1196549.0  48888.0      0.948750   \n",
       "2   0.269885  0.150965  20596.0  10242.0  1203290.0  51160.0      0.952227   \n",
       "3   0.284037  0.151777  20872.0  10587.0  1202945.0  50884.0      0.952173   \n",
       "4   0.295657  0.152079  19638.0   8253.0  1205279.0  52118.0      0.953029   \n",
       "5   0.306436  0.149519  18706.0   7240.0  1206292.0  53050.0      0.953092   \n",
       "6   0.315537  0.149828  17895.0   6485.0  1207047.0  53861.0      0.953049   \n",
       "7   0.324752  0.151381  17940.0   7053.0  1206479.0  53816.0      0.952642   \n",
       "8   0.332372  0.149976  18722.0   7389.0  1206143.0  53034.0      0.952989   \n",
       "9   0.341287  0.148263  19931.0   8035.0  1205497.0  51825.0      0.953427   \n",
       "10  0.348851  0.150312  21521.0  10544.0  1202988.0  50235.0      0.952712   \n",
       "\n",
       "    val_precision  val_recall  \n",
       "0        0.472346    0.329199  \n",
       "1        0.573838    0.318691  \n",
       "2        0.667877    0.287028  \n",
       "3        0.663467    0.290875  \n",
       "4        0.704098    0.273677  \n",
       "5        0.720959    0.260689  \n",
       "6        0.734003    0.249387  \n",
       "7        0.717801    0.250014  \n",
       "8        0.717016    0.260912  \n",
       "9        0.712687    0.277761  \n",
       "10       0.671168    0.299919  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history_model_2_fine_multi_optimizer.history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('env_similar-products')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3a9fdba9d57aea1bb5c6986083e3594030ae55b020a0216061e1820b16640168"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
