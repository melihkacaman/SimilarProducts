{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Used Dataset \n",
    "- ../datasets/attribute_set/custom_attr.csv  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import read_csv_with_dtypes \n",
    "import pandas as pd \n",
    "\n",
    "data = read_csv_with_dtypes(\"../datasets/attribute_set/custom_attr.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 289222 entries, 0 to 289221\n",
      "Columns: 1001 entries, paths to zippered\n",
      "dtypes: int8(1000), object(1)\n",
      "memory usage: 278.0+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paths</th>\n",
       "      <th>a-line</th>\n",
       "      <th>abstract</th>\n",
       "      <th>abstract chevron</th>\n",
       "      <th>abstract chevron print</th>\n",
       "      <th>abstract diamond</th>\n",
       "      <th>abstract floral</th>\n",
       "      <th>abstract floral print</th>\n",
       "      <th>abstract geo</th>\n",
       "      <th>abstract geo print</th>\n",
       "      <th>...</th>\n",
       "      <th>zeppelin</th>\n",
       "      <th>zig</th>\n",
       "      <th>zigzag</th>\n",
       "      <th>zip</th>\n",
       "      <th>zip-front</th>\n",
       "      <th>zip-pocket</th>\n",
       "      <th>zip-up</th>\n",
       "      <th>zipped</th>\n",
       "      <th>zipper</th>\n",
       "      <th>zippered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000001.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000002.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000003.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000004.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000005.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             paths  a-line  abstract  \\\n",
       "0  img/Sheer_Pleated-Front_Blouse/img_00000001.jpg       0         0   \n",
       "1  img/Sheer_Pleated-Front_Blouse/img_00000002.jpg       0         0   \n",
       "2  img/Sheer_Pleated-Front_Blouse/img_00000003.jpg       0         0   \n",
       "3  img/Sheer_Pleated-Front_Blouse/img_00000004.jpg       0         0   \n",
       "4  img/Sheer_Pleated-Front_Blouse/img_00000005.jpg       0         0   \n",
       "\n",
       "   abstract chevron  abstract chevron print  abstract diamond  \\\n",
       "0                 0                       0                 0   \n",
       "1                 0                       0                 0   \n",
       "2                 0                       0                 0   \n",
       "3                 0                       0                 0   \n",
       "4                 0                       0                 0   \n",
       "\n",
       "   abstract floral  abstract floral print  abstract geo  abstract geo print  \\\n",
       "0                0                      0             0                   0   \n",
       "1                0                      0             0                   0   \n",
       "2                0                      0             0                   0   \n",
       "3                0                      0             0                   0   \n",
       "4                0                      0             0                   0   \n",
       "\n",
       "   ...  zeppelin  zig  zigzag  zip  zip-front  zip-pocket  zip-up  zipped  \\\n",
       "0  ...         0    0       0    0          0           0       0       0   \n",
       "1  ...         0    0       0    0          0           0       0       0   \n",
       "2  ...         0    0       0    0          0           0       0       0   \n",
       "3  ...         0    0       0    0          0           0       0       0   \n",
       "4  ...         0    0       0    0          0           0       0       0   \n",
       "\n",
       "   zipper  zippered  \n",
       "0       0         0  \n",
       "1       0         0  \n",
       "2       0         0  \n",
       "3       0         0  \n",
       "4       0         0  \n",
       "\n",
       "[5 rows x 1001 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a-line',\n",
       " 'abstract',\n",
       " 'abstract chevron',\n",
       " 'abstract chevron print',\n",
       " 'abstract diamond']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABELS = list(data.columns.values[1:])\n",
    "LABELS[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../datasets/big_ds/img-001/'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base = \"../datasets/big_ds/img-001/\" \n",
    "base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paths</th>\n",
       "      <th>a-line</th>\n",
       "      <th>abstract</th>\n",
       "      <th>abstract chevron</th>\n",
       "      <th>abstract chevron print</th>\n",
       "      <th>abstract diamond</th>\n",
       "      <th>abstract floral</th>\n",
       "      <th>abstract floral print</th>\n",
       "      <th>abstract geo</th>\n",
       "      <th>abstract geo print</th>\n",
       "      <th>...</th>\n",
       "      <th>zeppelin</th>\n",
       "      <th>zig</th>\n",
       "      <th>zigzag</th>\n",
       "      <th>zip</th>\n",
       "      <th>zip-front</th>\n",
       "      <th>zip-pocket</th>\n",
       "      <th>zip-up</th>\n",
       "      <th>zipped</th>\n",
       "      <th>zipper</th>\n",
       "      <th>zippered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../datasets/big_ds/img-001/img/Sheer_Pleated-F...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../datasets/big_ds/img-001/img/Sheer_Pleated-F...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../datasets/big_ds/img-001/img/Sheer_Pleated-F...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../datasets/big_ds/img-001/img/Sheer_Pleated-F...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../datasets/big_ds/img-001/img/Sheer_Pleated-F...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               paths  a-line  abstract  \\\n",
       "0  ../datasets/big_ds/img-001/img/Sheer_Pleated-F...       0         0   \n",
       "1  ../datasets/big_ds/img-001/img/Sheer_Pleated-F...       0         0   \n",
       "2  ../datasets/big_ds/img-001/img/Sheer_Pleated-F...       0         0   \n",
       "3  ../datasets/big_ds/img-001/img/Sheer_Pleated-F...       0         0   \n",
       "4  ../datasets/big_ds/img-001/img/Sheer_Pleated-F...       0         0   \n",
       "\n",
       "   abstract chevron  abstract chevron print  abstract diamond  \\\n",
       "0                 0                       0                 0   \n",
       "1                 0                       0                 0   \n",
       "2                 0                       0                 0   \n",
       "3                 0                       0                 0   \n",
       "4                 0                       0                 0   \n",
       "\n",
       "   abstract floral  abstract floral print  abstract geo  abstract geo print  \\\n",
       "0                0                      0             0                   0   \n",
       "1                0                      0             0                   0   \n",
       "2                0                      0             0                   0   \n",
       "3                0                      0             0                   0   \n",
       "4                0                      0             0                   0   \n",
       "\n",
       "   ...  zeppelin  zig  zigzag  zip  zip-front  zip-pocket  zip-up  zipped  \\\n",
       "0  ...         0    0       0    0          0           0       0       0   \n",
       "1  ...         0    0       0    0          0           0       0       0   \n",
       "2  ...         0    0       0    0          0           0       0       0   \n",
       "3  ...         0    0       0    0          0           0       0       0   \n",
       "4  ...         0    0       0    0          0           0       0       0   \n",
       "\n",
       "   zipper  zippered  \n",
       "0       0         0  \n",
       "1       0         0  \n",
       "2       0         0  \n",
       "3       0         0  \n",
       "4       0         0  \n",
       "\n",
       "[5 rows x 1001 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.paths = data.paths.apply(lambda x: base + x) \n",
    "data.head() "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data Pipeline by using tf.data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['../datasets/big_ds/img-001/img/Sheer_Pleated-Front_Blouse/img_00000001.jpg',\n",
       "       '../datasets/big_ds/img-001/img/Sheer_Pleated-Front_Blouse/img_00000002.jpg',\n",
       "       '../datasets/big_ds/img-001/img/Sheer_Pleated-Front_Blouse/img_00000003.jpg',\n",
       "       '../datasets/big_ds/img-001/img/Sheer_Pleated-Front_Blouse/img_00000004.jpg',\n",
       "       '../datasets/big_ds/img-001/img/Sheer_Pleated-Front_Blouse/img_00000005.jpg'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fnames = data.paths.to_numpy()  \n",
    "fnames[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "\n",
    "ds_size = data.shape[0] \n",
    "number_of_selected_samples = 2000 \n",
    "\n",
    "filelist_ds = tf.data.Dataset.from_tensor_slices(fnames[:number_of_selected_samples]) \n",
    "\n",
    "filelist_ds.cardinality().numpy() "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom tf Helpers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(file_path):\n",
    "    \"\"\"\n",
    "        file_path: the file path for the image that you want to select\n",
    "    \"\"\"\n",
    "    labels = data.loc[data.paths == file_path].to_numpy().squeeze()[1:].astype(\"float32\")\n",
    "    return tf.convert_to_tensor(labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_label(fnames[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize and scale the images so that we can save time in training  \n",
    "IMG_WIDTH, IMG_HEIGHT = 64, 64 \n",
    "def decode_img(img):\n",
    "    \"\"\"\n",
    "        img: img is the image \n",
    "    \"\"\" \n",
    "    #color images \n",
    "    img = tf.image.decode_jpeg(img, channels=3) \n",
    "    img = tf.image.convert_image_dtype(img, tf.float32) \n",
    "    return tf.image.resize(img, [IMG_WIDTH, IMG_HEIGHT]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_images_labels(file_path: tf.Tensor): \n",
    "    label = get_label(file_path) \n",
    "    img = tf.io.read_file(file_path) \n",
    "    img = decode_img(img) \n",
    "    return img, label "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Test Split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.80 \n",
    "ds_train = filelist_ds.take(int(number_of_selected_samples * train_ratio)) \n",
    "ds_test = filelist_ds.skip(int(number_of_selected_samples * train_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process All the Images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = ds_train.map(lambda x: \n",
    "                        tf.py_function(func=combine_images_labels, \n",
    "                                       inp=[x], # input of the function \n",
    "                                       Tout=(tf.float32,tf.int64)),  # return type \n",
    "                        num_parallel_calls=tf.data.AUTOTUNE, # parallelizing data extraction \n",
    "                        deterministic=False \n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test= ds_test.map(lambda x: tf.py_function(func=combine_images_labels,\n",
    "          inp=[x], Tout=(tf.float32,tf.int64)),\n",
    "          num_parallel_calls=tf.data.AUTOTUNE,\n",
    "          deterministic=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data Pipeline \n",
    "\n",
    "- **batch**(): Combines consecutive elements of this dataset into batches.\n",
    "- **cache**(): Caches the elements in this dataset. he first time the dataset is iterated over, its elements will be cached either in the specified file or in memory.Subsequent iterations will use the cached data.\n",
    "- **prefetch**(): Creates a Dataset that prefetches elements from this dataset. Most dataset input pipelines should end with a call to *prefetch*. This allows later elements to be prepared while the current element is being processed. This often improves latency and throughput, at the cost of using additional memory to store prefetched elements.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train_batched = ds_train.batch(BATCH_SIZE).cache().prefetch(tf.data.experimental.AUTOTUNE) \n",
    "ds_test_batched = ds_test.batch(BATCH_SIZE).cache().prefetch(tf.data.experimental.AUTOTUNE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train_batched.cardinality().numpy() "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Keras CNN model by using Transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58889256/58889256 [==============================] - 12s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras \n",
    "base_model = keras.applications.VGG16(\n",
    "    weights=\"imagenet\", # load weights pre-trained on ImageNet. \n",
    "    input_shape=(IMG_WIDTH, IMG_HEIGHT, 3), # VGG16 expects min 32 x 32 \n",
    "    include_top = False # do not include output layer of the image net vgg \n",
    ")\n",
    "base_model.trainable = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nr_of_classes = len(LABELS) \n",
    "nr_of_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(IMG_WIDTH,IMG_HEIGHT,3)) \n",
    "x = base_model(inputs) \n",
    "x = keras.layers.GlobalAveragePooling2D()(x) \n",
    "\n",
    "initializer = tf.keras.initializers.GlorotUniform(seed=42) \n",
    "activation = tf.keras.activations.sigmoid  \n",
    "\n",
    "outputs = keras.layers.Dense(nr_of_classes,\n",
    "                             kernel_initializer=initializer, \n",
    "                             activation=activation)(x) \n",
    "\n",
    "model = keras.Model(inputs, outputs) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile and Train the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.Adam(),\n",
    "              loss=keras.losses.BinaryCrossentropy(), # default from_logits=False\n",
    "              metrics=[keras.metrics.BinaryAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    }
   ],
   "source": [
    "model.fit(ds_train_batched, \n",
    "        validation_data=ds_test_batched, \n",
    "        epochs=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_similar-products",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d2ae175228e4b907f6759aae1200b3a8fda51833cb8d87ddc125794bd32e5598"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
